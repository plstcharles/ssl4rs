# @package _global_
#
# This root config is associated to the 'data_profiler.py' entrypoint provided with the framework.
#
# Note1: when launching with this config, you likely need an experiment subconfig! For example:
#     python data_profiler.py experiment=example_mnist_classif
#
# Note2: the default callbacks and loggers are not included here, as they should not be needed (we
#   do not even create a trainer object in the entrypoint mentioned above).

defaults:
  - utils: default.yaml # utility configs contain general-use-but-not-so-important settings
  - output: default.yaml # output configs define the root path and name patterns to use for logging
  - data: default.yaml # data configs define the datamodule and dataloaders to instantiate
  - model: null # we should not actually need a model config for the data profiler
  - callbacks: null # we should not actually need trainer callbacks for the data profiler
  - logger: null # we should not actually need trainer loggers for the data profiler
  - trainer: null # we should not actually need a trainer config for the data profiler
  - _self_ # moved here so that the experiment config can override the profiler settings, if needed
  - experiment: null # experiment configs allow for overrides and version control of all settings
  - optional local: default.yaml # optional overriding config for machine/user specific settings
  - debug: null # debugging configs allow for extra logging and deactivation of optimization stuff

run_type: profiler

profiler:
  dataloader_type: train # dataloader to be used for profiling (likely one of train/valid/test)
  use_parser: False # toggles whether to profile the dataset parser or the dataloader
  batch_count: 10 # batches to fetch before breaking off the loop (-1 or null = full run)
  loop_count: 1 # number of loops to complete over the same dataloader to get average timings
