# @package _global_
#
# This root config is associated to the 'data_profiler.py' entrypoint provided with the framework.
#
# Note1: when launching with this config, you likely need an experiment subconfig! For example:
#     python data_profiler.py experiment=example_mnist_classif
#
# Note2: the default callbacks and loggers are not included here, as they should not be needed (we
#   do not even create a trainer object in the entrypoint mentioned above).

defaults:
  - _self_
  - utils: default.yaml # utility configs contain general-use-but-not-so-important settings
  - output: default.yaml # output configs define the root path and name patterns to use for logging
  - data: default.yaml # data configs define the datamodule and dataloaders to instantiate
  - model: default.yaml # model configs define the LightningModule-derived models to instantiate
  - callbacks: null # we should not actually need trainer callbacks for the data profiler
  - logger: null # we should not actually need trainer loggers for the data profiler
  - trainer: default.yaml # trainer configs define the (lightning-derived) trainer to instantiate
  - experiment: null # experiment configs allow for overrides and version control of all settings
  - optional local: default.yaml # optional overriding config for machine/user specific settings
  - debug: null # debugging configs allow for extra logging and deactivation of optimization stuff

experiment_name: default # defines the experiment name used in various output/logging paths
run_type: profiler
run_name: ${utils.curr_timestamp} # defines the run name used in various output/logging paths
job_name: ${oc.select:hydra.job.num,0} # defines the job name used in various output/logging paths

profiler:
  default_dataloader_type: train # loader used for data profiling (likely one of train/valid/test)
  valid_dataloader_type: valid # eval loader used for model profiling (likely valid/test)
  use_parser: False # toggles whether to profile the dataset parser or the dataloader
  display_key: # if we want to try to render+display a tensor image while running, specify it here
  display_wait_time: 0 # time to display images for, when toggled above (in msecs, and 0 = block)
  batch_count: null # batches to fetch before breaking off the loop (-1 or null = full run)
  loop_count: 3 # number of loops to complete over the same dataloader to get average timings
