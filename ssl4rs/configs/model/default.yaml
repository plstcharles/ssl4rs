# @package _global_

# this config specifies info for the main LightningModule used for its model training/inference logic

model:
  _target_: ??? # MANDATORY class to be instantiated (should be derived from a pl.LightningModule)

target_metric: val/loss # name of the metric we will be targeting for hparam optimization (if any)
target_metric_mode: min # optimization mode of the target metric defined above (should be min or max)

compile_model: False # toggles whether the Lightning module we just instantiated should be compiled
# see https://pytorch.org/get-started/pytorch-2.0/#user-experience for more information!
compile_model_kwargs: # here, we'll provide any extra kwargs to forward to PyTorch for compilation
  mode: reduce-overhead # if this requires too much extra memory, switch to 'default'
